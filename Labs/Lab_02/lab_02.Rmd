---
title: 'Lab 2: Data wrangling'
output: html_document
---
In this first "real" lab we'll go over one of the most important skills in data science: Data Wrangling. It's the art of cleaning and manipulating our data to prepare it for our analyses and visualizations. A common estimate is that for most machine-learning projects, 80% of the time is spent on data wrangling, and the remaining 20% is spent on actually setting up and training the machine learning model.

We'll go over three main things today: basic data manipulation skills, web scraping, and loading and combining datasets.

We'll start with basic data manipulation skills. It is useful to FIRST try to visualize in our head what we want to do with the data, and THEN look for the code that can do that for us. Once you learn some useful functions, you will be able to combine them to manipulate the data to your will like a wizard.

You can find a list of our spells... ehhhm, functions [here](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf).


And a list of other useful spellbooks (cheat sheets) [here](https://rstudio.com/resources/cheatsheets/). 


### 1. Getting an overview of the data
First we'll explore different ways to get an overview of the dataset.
Let's use the gapminder dataset, available in the `dslabs` package. Because the data is available in the package, we can load it by simply using `data(gapminder)`. First we'll look at the dataset to see what it contains. We will use `summary()`, `head()` and `str()`.

##### 1) What type of information do each one of these functions provide about our dataset?

##### 2) How is the dataset ordered?

##### 3) What range of years does our dataset contain?

```{r, message=FALSE, first-plot}
#install.packages('dplyr')
#install.packages('dslabs')
#install.packages('tidyr')
library(tidyr)
library(dplyr)
library(dslabs)
library(rvest)
data(gapminder)

df <- gapminder

```


### 2. Ordering and subsetting our dataset

We can subset our dataset in different ways.

For example, the brute-force approach: we can select the cell in row 1, column 3 using `gapminder[1,3]`. We can also select a range of rows using `:`; i.e. we can select rows 2 to 5, column 1 using `gapminder[2:5,1]`.

We can use the `filter()` function to select rows according to values of a column, and we can use `select()` to select only specific columns according to their name.

We can also order a data frame using `arrange()`

##### 1) Create a data frame called `df2` that is ordered so that it shows the data for each country (all years), then the next country (all years), etc.

##### 2) Create a data frame called `algeriagdp` that includes only year and GDP data for Algeria.

##### 3) Think of 2 other ways we could have achieved the same result for #2. You can code them if you want, but the main task is to think of the process.

```{r}
#1


#2


#3


```

### 2.1 (optional) The extremely useful `which()` function.

The `which()` function returns the index of rows in a data frame that meet a certain criteria. For example, if we want to know the index of the rows for Algeria, we can type the following:

```{r}
which(gapminder$country == "Algeria")
```

We can use this to select rows within our data frame by using brackets `[ ]` and placing our `which()` function where we would place the row number.
```{r}
head(gapminder[which(gapminder$country == "Algeria"), ])

# Note that R requires us to put a comma afterwards to indicate the column numbers. We can leave it blank to indicate we want all columns. We can also indicate the columns we want, either using the column number or by putting the column name in brackets, e.g. "infant_mortality"

head(gapminder[which(gapminder$country == "Algeria"), "infant_mortality"])
```

We can also use this to change the values of specific rows or cells. For example, Swaziland recently changed the country name to Eswatini. If we want to make this change, we can do the following:

```{r}
gapminder$country = as.character(gapminder$country)

gapminder$country[gapminder$country == "Swaziland"] = "Eswatini"

gapminder$country = as.factor(gapminder$country)
```



### 3. The pipe operator %>%

To generate the result above, you may have needed steps in between. We can use the pipe operator `%>%` to avoid using intermediate steps. This makes for much more intuitive and fun data wrangling.

For example, we can create the data frame mentioned above in an elegant, intuitive way:
```{r}
algeriagdp <- gapminder %>% 
  filter(country == 'Algeria') %>% 
  select (gdp,year)
```

##### 1) Using the pipe operator, create a dataset that includes country, year, gdp and population for countries in South-Eastern Asia between 1965 and 2010. Order the data frame by country, then year. Try to do it all in one command, starting from the `gapminder` dataset, using the pipe operator. Confirm that your code is doing what it's supposed to.

```{r}
#asiadf <- gapminder %>% #your code here

```

### 4. Creating variables

We can create variables using `mutate()`.

##### 1) Create a variable with the approximate number of women in the population. Assume that 52% of the population are women.

##### 2) Calculate an approximation of the number of children born each year based on the `fertility` column, which displays the expected number of children per woman over their reproductive life.
For this, assume an average reproductive life of 25 years.

##### 3) Look up and explore the function `lag()`. Use it to calculate the change in population from the year prior, and assign it to a column called `popchange`.

```{r}
#1

#2

#3


```


### 5. Summary

As we saw in class, the function `summarize()` provides a useful way to combine data from different rows.

##### 1) Create a dataset with the total world population by year.

##### 2) Create a dataset with the gdp per capita by world region for the year 2010. Be careful of the order when using the pipe operator `%>%`

##### 3) Calculate the increase in gdp per capita from the year prior by region and year. Explain any assumptions you had to make.

```{r}
#1

#2

#3

```


### 6. Web scraping

We'll go over this example from class a bit slower so we can understand what the different functions are doing and what each object contains.

```{r}
# Wikipedia article to scrape
url <- "https://en.wikipedia.org/w/index.php?title=2009_swine_flu_pandemic_tables&oldid=950511922"

# If you are unable to access Wikipedia, uncomment and use the following 
# line to read in the saved HTML file of the webpage
# url = "h1n1_wiki_tables.html"

# Extract all tables in the page
tab = read_html(url) %>% html_nodes("table")

tab

cases_df <- tab %>% .[1] %>% html_table %>% .[[1]]
deaths_df <- tab %>% .[2] %>% html_table %>% .[[1]]


# Variable names to use for the table of case counts
case_names <- c("by_date", "by_continent", "country", "first_case",
                "April", "May", "June", "July", "August", "latest")
# Variable names to use for the table of death counts
death_names <- c("by_date", "by_continent", "country", "first_death",
                 "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")

cases_df <- tab %>% .[1] %>% html_table %>% .[[1]] %>% setNames(case_names)
deaths_df <- tab %>% .[2] %>% html_table %>% .[[1]] %>% setNames(death_names)

```

Now let's give it a try ourselves. Let's try to scrape the table with the human development index from the following Wikipedia page: https://en.wikipedia.org/wiki/List_of_countries_by_Human_Development_Index



Some resources on web scraping with R: 
https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/

https://www.youtube.com/watch?v=4IYfYx4yoAI

```{r}
#install.packages('rvest')
library(rvest)

url <- "https://en.wikipedia.org/w/index.php?title=List_of_countries_by_Human_Development_Index&oldid=1043741772"

# If you are unable to access Wikipedia, uncomment and use the following 
# line to read in the saved HTML file of the webpage
# url = "hdi_wiki_list.html"

```

##### 1) How many columns does our table include? Do we need all of them? Select only the ones that we need.

```{r}
colnames(table2)

```


##### 2) Now let's join the table we just created with a table that includes gdp per capita by country for the last year that it's available, which is 2011. What will we join by? What type of join function is most appropriate?

```{r}


```


### 7. Date manipulation

Let's use the table we scraped earlier as an example (the `cases_df` data frame) with the date of the first swine flu case in each country.

Calling the `str()` function, we can see that the column for the date of the first case is a string, which means that R understands the contents as a set of characters and not as a date. So if we try to order our data frame by the date of the first case, R won't do a good job.

But we can use the function ymd() to convert into a date. Then we can use the converted date column to arrange our data frame according to the date of the first case.

```{r}
str(cases_df)
```

##### 1) Convert the `first_case` column to a date and arrange the data frame by the `first_case` date.

##### 2) Calculate the time difference between each country's first case and the previous country's first case using the `lag()` function, and save it into a column called `first_case_diff`.

```{r}
#install.packages("lubridate")
library(lubridate)

```

